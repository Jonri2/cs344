{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1\n",
    "Below is the code for a spam mail filter as specified at http://www.paulgraham.com/spam.html. I took the approach of\n",
    "building a class for the filter which is initialized with a corpus of regular mail and a corpus of spam mail. When\n",
    "initialized, it computes the probabilities that a token that is in one of the corpora is spam. That information is then\n",
    "used to compute the probability that a new message that is sent to the filter is spam.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "class Filter:\n",
    "    \"\"\"A filter for spam mail. Takes a corpus of regular and spam mail and\n",
    "    calculates the probability that a new message is spam based on the\n",
    "    common words in each\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mail_corpus, spam_corpus):\n",
    "        self.mail = mail_corpus\n",
    "        self.spam = spam_corpus\n",
    "        self.good = {}\n",
    "        self.bad = {}\n",
    "        self.probability = {}\n",
    "        self.create_mail_hash(mail_corpus)\n",
    "        self.create_spam_hash(spam_corpus)\n",
    "        self.create_probability_hash()\n",
    "\n",
    "    def create_mail_hash(self, mail_corpus):\n",
    "        \"\"\"Creates a dictionary of the number of occurrences of tokens from regular mail\"\"\"\n",
    "        for message in mail_corpus:\n",
    "            for word in message:\n",
    "                wordVal = self.good.get(word, 0)\n",
    "                self.good[word] = wordVal + 1\n",
    "\n",
    "    def create_spam_hash(self, spam_corpus):\n",
    "        \"\"\"Creates a dictionary of the number of occurrences of tokens from spam mail\"\"\"\n",
    "        for message in spam_corpus:\n",
    "            for word in message:\n",
    "                wordVal = self.bad.get(word, 0)\n",
    "                self.bad[word] = wordVal + 1\n",
    "\n",
    "    def create_probability_hash(self):\n",
    "        \"\"\"Creates a dictionary of the probability that a word is spam\"\"\"\n",
    "        for word in self.good:\n",
    "            self.probability[word] = self.compute_probability(word)\n",
    "\n",
    "        for word in self.bad:\n",
    "            if self.good.get(word, 0) == 0:\n",
    "                self.probability[word] = self.compute_probability(word)\n",
    "\n",
    "    def compute_probability(self, word):\n",
    "        \"\"\"Computes the probability that a word is spam using Bayesian statistics\"\"\"\n",
    "        g = b = 0\n",
    "        ngood = len(self.mail)\n",
    "        nbad = len(self.spam)\n",
    "        if self.good.get(word, 0) > 0:\n",
    "            g = 2 * self.good[word]\n",
    "        if self.bad.get(word, 0) > 0:\n",
    "            b = self.bad[word]\n",
    "        if g + b >= 1:\n",
    "            return max(0.01, min(0.99, float(min(1, b / nbad) / (min(1, g / ngood) + min(1, b / nbad)))))\n",
    "        return 0\n",
    "\n",
    "    def filter(self, message):\n",
    "        \"\"\"Computes the probability that a new message is spam\"\"\"\n",
    "        message_probs = []\n",
    "        for word in message:\n",
    "            word_prob = self.compute_probability(word)\n",
    "            if word_prob == 0:\n",
    "                word_prob = 0.4\n",
    "            message_probs.append(word_prob)\n",
    "\n",
    "        prod = prod_comp = 1\n",
    "        for prob in message_probs:\n",
    "            prod *= prob\n",
    "            prod_comp *= 1 - prob\n",
    "        return prod / (prod + prod_comp)\n",
    "\n",
    "    def get_probabilities(self):\n",
    "        return self.probability\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This filter uses a Bayesian approach for the SPAM model because the filter can combine new data with existing data to\n",
    "compute and update probabilities simply by adding more messages to each corpus. This way the filter can adjust the\n",
    "probabilities when new spam information is received."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'do': 0.3333333333333333, 'i': 0.01, 'like': 0.3333333333333333, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01, 'I': 0.99, 'am': 0.99, 'spam': 0.99, 'not': 0.99, 'that': 0.99, 'spamiam': 0.99}\n",
      "0.9999999999989378\n",
      "0.9999999583591874\n",
      "2.6288392819642677e-11\n",
      "0.005025125628140704\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "spam_filter = Filter(ham_corpus, spam_corpus)\n",
    "\n",
    "# Print the table of probabilities\n",
    "print(spam_filter.get_probabilities())\n",
    "\n",
    "# Print the probability that each message is spam\n",
    "print(spam_filter.filter(spam_corpus[0]))\n",
    "print(spam_filter.filter(spam_corpus[1]))\n",
    "print(spam_filter.filter(ham_corpus[0]))\n",
    "print(spam_filter.filter(ham_corpus[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These probabilities are really close to either extreme, which makes sense since they were used to initialize the filter.\n",
    "\n",
    "# 2.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from probability import BayesNet, enumeration_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "grass = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.10, F: 0.50}),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.9, (F, T): 0.9, (F, F): 0.0})\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b. The number of independent values in the joint probability distribution = 2<sup>4</sup> = 16 since there are 4\n",
    "independent variables in the distribution.\n",
    "\n",
    "c. The number of independent values in the Bayesian Network = 9 since the causal relationships in the network simplify\n",
    "it, allowing for less stored values than for a joint probability distribution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf{P}(Cloudy)\n",
    "    \\end{aligned}$\n",
    "\n",
    "Given in table: <0.5, 0.5>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.5, True: 0.5\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(enumeration_ask('Cloudy', dict(), grass).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf{P}(Sprinkler | Cloudy)\n",
    "    \\end{aligned}$\n",
    "\n",
    "Given in table: <0.1, 0.9>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.9, True: 0.1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), grass).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf{P}(Cloudy | Sprinkler \\land \\neg Rain)\n",
    "        &= \\alpha *\\textbf{P}(C, S, \\neg R) \\\\\n",
    "        &= \\alpha *\\textbf{P}(C) * P(S|C) * P(\\neg R|C) \\\\\n",
    "        &= \\alpha *\\langle (0.5 * 0.1 * 0.2), (0.5 * 0.5 * 0.8) \\rangle \\\\\n",
    "        &= \\alpha *\\langle 0.01, 0.2 \\rangle \\\\\n",
    "        &= \\langle 0.0476, 0.952 \\rangle\n",
    "    \\end{aligned}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.952, True: 0.0476\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), grass).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf{P}(WetGrass | Cloudy \\land Sprinkler \\land Rain)\n",
    "        &= \\alpha * \\textbf{P}(WG, C, S, R) \\\\\n",
    "        &= \\alpha * \\textbf{P}(WG|S \\land R) * P(S|C) * P(R|C) * P(C) \\\\\n",
    "        &= \\alpha * \\langle (0.99 * 0.1 * 0.8 * 0.5), (0.01 * 0.1 * 0.8 * 0.5) \\rangle \\\\\n",
    "        &= \\alpha * \\langle 0.0396, 0.0004 \\rangle \\\\\n",
    "        &= \\langle0.99, 0.01\\rangle\n",
    "    \\end{aligned}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.01, True: 0.99\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), grass).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf{P}(Cloudy | \\neg WetGrass)\n",
    "        &= \\alpha * \\sum_S\\sum_R\\textbf{P}(C,S,R,\\neg WG) \\\\\n",
    "        &= \\alpha * \\sum_S\\sum_R\\textbf{P}(C) * P(S|C) * P(R|C) * P(\\neg WG|S,R) \\\\\n",
    "        &= \\alpha * \\langle (P(C) * P(S|C) * P(R|C) * P(\\neg WG|S,R) + P(C) * P(\\neg S|C) * P(R|C) * P(\\neg WG|\\neg S,R) \\\\\n",
    "        &+ P(C) * P(S|C) * P(\\neg R|C) * P(\\neg WG|S,\\neg R) + P(C) * P(\\neg S|C) * P(\\neg R|C) * P(\\neg WG|\\neg S,\\neg R)), \\\\\n",
    "        &P(\\neg C) * P(S|\\neg C) * P(R|\\neg C) * P(\\neg WG|S,R) + P(\\neg C) * P(\\neg S|\\neg C) * P(R|\\neg C) * P(\\neg WG|\\neg S,R) \\\\\n",
    "        &+ P(\\neg C) * P(S|\\neg C) * P(\\neg R|\\neg C) * P(\\neg WG|S,\\neg R) + P(\\neg C) * P(\\neg S|\\neg C) * P(\\neg R|\\neg C) * P(\\neg WG|\\neg S,\\neg R)) \\rangle \\\\\n",
    "        &= \\alpha * \\langle (0.5 * 0.1 * 0.8 * 0.01 + 0.5 * 0.9 * 0.8 * 0.1 + 0.5 * 0.1 * 0.2 * 0.1 + 0.5 * 0.9 * 0.2 * 1.0), \\\\\n",
    "        &(0.5 * 0.5 * 0.2 * 0.01 + 0.5 * 0.5 * 0.2 * 0.1 + 0.5 * 0.5 * 0.8 * 0.1 + 0.5 * 0.5 * 0.8 * 1.0) \\rangle \\\\\n",
    "        &= \\alpha * \\langle 0.1274, 0.2255\\rangle \\\\\n",
    "        &= \\langle 0.361, 0.639\\rangle \\\\\n",
    "    \\end{aligned}$\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.639, True: 0.361\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), grass).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}