{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "## 3.1\n",
    "\n",
    "$\\begin{aligned}\n",
    "    \\textbf Gain(Price?)\n",
    "        &= Entropy(Restaurant) - Remainder(Price?) \\\\\n",
    "        &= -(6/12*lg(6/12)+6/12*lg(6/12))-((7/12) Entropy(\\$)+(2/12) Entropy(\\$\\$)+(3/12) Entropy(\\$\\$\\$)) \\\\\n",
    "        &= 1.0 - (7/12*(-(3/7*lg(3/7)+4/7*lg(4/7)))+2/12*(-(2/2*lg(2/2)+0/2*lg(0/2)))+3/12*(-(1/3*lg(1/3)+2/3*lg(2/3)))) \\\\\n",
    "        &= 1.0 - (7/12*0.985 + 2/12*0.0 + 3/12*0.918) \\\\\n",
    "        &= 1.0 - 0.804 \\\\\n",
    "        &= 0.196\n",
    "    \\end{aligned}$\n",
    "    \n",
    "The information gain provided by using the price attribute as the root of the decision tree is 0.196 bits. This is more\n",
    "valuable than the Types? question which gained 0 bits of information but less valuable than the Patrons? question which\n",
    "gained 0.54 bits of information.\n",
    "\n",
    "## 3.2\n",
    "[Reference](http://mnemstudio.org/neural-networks-multilayer-perceptrons.htm)\n",
    "![alt text](./Homework3_XOR.PNG)\n",
    "By loosening the constraints of sequential networks, the XOR function can be simplified to just 1 node in the hidden\n",
    "layer and no bias in the input layer. This is done by allowing the input layer to impact both the hidden layer and the\n",
    "output layer rather than having the network be sequential. The weights for the input nodes are 1 and the weight for the\n",
    "node in the hidden layer is -2. The node in the hidden layer is only activated if both of the input nodes are 1, meaning\n",
    "that -2 is only added to the output node if both input nodes are 1, fulfilling the requirements of the XOR function.\n",
    "\n",
    "## 3.3\n",
    "\n",
    "## a. Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Boston Housing Dataset Dimensions:\n",
      "\tTrain X: (404, 13)\n",
      "\tTrain Targets: (404,)\n",
      "\tTest X: (102, 13)\n",
      "\tTest Targets: (102,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "(x_train, train_targets), (x_test, test_targets) = boston_housing.load_data()\n",
    "print(\"Boston Housing Dataset Dimensions:\")\n",
    "print(\"\\tTrain X:\", x_train.shape)\n",
    "print(\"\\tTrain Targets:\", train_targets.shape)\n",
    "print(\"\\tTest X:\", x_test.shape)\n",
    "print(\"\\tTest Targets:\", test_targets.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b. Datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "houses_train = pd.DataFrame(x_train)\n",
    "houses_test = pd.DataFrame(x_test)\n",
    "houses_train[\"Targets\"] = train_targets\n",
    "houses_test[\"Targets\"] = test_targets\n",
    "houses_validate = houses_train.tail(101)\n",
    "houses_train = houses_train.head(303)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The targets are added to the DataFrame and the validation set is taken from the last fourth of the training set.\n",
    "\n",
    "## c. Synthetic Feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def add_synthetic_feature(source_data):\n",
    "    data = source_data.copy()\n",
    "    data[\"Aged Value\"] = data[12] * (1 - data[6])\n",
    "    return data\n",
    "\n",
    "houses_train = add_synthetic_feature(houses_train)\n",
    "houses_validate = add_synthetic_feature(houses_validate)\n",
    "houses_test = add_synthetic_feature(houses_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I created the aged value synthetic feature which is the median value of the house multiplied by the inverse of the \n",
    "proportion of houses built before 1940, meaning that values are higher for newer houses. This feature could be useful\n",
    "because it could help indicate future value, since older houses are more likely to have issues."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}